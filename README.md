# Spike AI Builder Challenge ‚Äî Analytics & SEO Assistant Agent ‚úÖ

‚ö†Ô∏è **Important ‚Äî wait for server startup before issuing requests**

When you start the application (for example via ` bash deploy.sh`), the server can take a few seconds to initialize and accept incoming requests. Please monitor the `server.log` file (e.g., `tail -f server.log`) and wait until you see the server report that it is running before executing the `curl` examples below.

A lightweight multi-agent analytics assistant that combines Google Sheets (Screaming Frog exports) and Google Analytics 4 data with an LLM to answer natural-language questions about SEO and analytics.

---

## Table of Contents
- [Project Overview](#project-overview)
- [Architecture Overview](#architecture-overview)
- [Setup & Run](#setup--run)
- [Data Source Integrations](#data-source-integrations)
- [Usage Examples](#usage-examples)
- [Assumptions & Limitations](#assumptions--limitations)
- [Security Notes](#security-notes)
- [Development Notes](#development-notes)

---

## Project Overview üí°

This project exposes a FastAPI endpoint that accepts a natural-language query and uses an orchestrator to route work to either:
- an SEO agent (operates on Screaming Frog exports stored in Google Sheets), or
- an Analytics agent (builds GA4 queries and executes them via the GA4 Data API), or
- both agents together and synthesizes a final natural-language answer using a configured LLM.

The system is intended for conversational analytics and exploratory SEO/GA4 queries.

---

## Architecture Overview üîß

- **FastAPI**: `app/main.py`, `app/api.py` ‚Äî exposes a `/query` endpoint.
- **Orchestrator**: `app/orchestrator.py` ‚Äî classifies intent (seo / analytics / both) and coordinates agents.
- **SEO Agent**: `app/agents/seo_agent.py` ‚Äî loads Screaming Frog data from Google Sheets (via `app/services/sheets_service.py`), asks the LLM to generate pandas code, executes it locally to compute results.
- **Analytics Agent**: `app/agents/analytics_agent.py` ‚Äî asks the LLM to turn a natural-language question into a GA4 query plan (JSON), validates the plan against `ga4_allowed_fields.txt`, and executes using `app/services/ga4_service.py` (GA4 Data API).
- **LLM Client**: `app/llm/client.py` ‚Äî wraps the LLM (configured via `LITELLM_API_KEY` env var, uses OpenAI-style client in this project).
- **Google Sheets**: `app/services/sheets_service.py` ‚Äî retrieves Screaming Frog sheet data and builds a union table used by the SEO Agent.

Data & control flow (simplified):
1. Client posts to `/query` with a `query` and optionally a `propertyId` (for GA4).
2. Orchestrator classifies intent using the LLM.
3. Agents run (SEO reads Sheets, Analytics runs GA4 query); their outputs are passed to the LLM to generate final answer.

---

## Setup & Run ‚öôÔ∏è

Prerequisites:
- Python 3.10+
- Service account JSON for Google APIs (must have access to the spreadsheet and GA4 property).
- Network access for the LLM endpoint and Google APIs.

Environment variables (example `.env`):
```
LITELLM_API_KEY="<your-llm-api-key>"
SPREADSHEET_URL="https://docs.google.com/spreadsheets/d/<id>/edit"
```

Important files required in the repository root:
- `credentials.json` ‚Äî Google service account key with access to Sheets and GA4.
- `ga4_allowed_fields.txt` ‚Äî allowed GA4 metrics and dimensions used to validate queries.

Install & run locally:
```bash
# create virtualenv
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt

# start server (development)
uvicorn app.main:app --host 0.0.0.0 --port 8080 --reload

# Or use the provided deploy script (macOS/Linux)
bash deploy.sh
```

---

## Data Source Integrations üîó

- **Google Sheets** (via `gspread` + service account): stores Screaming Frog exports. The `SEOAgent` expects a union table created from all worksheets; each sheet must include an `Address` column to be included in the union.
- **Google Analytics 4** (via `google-analytics-data` library): `AnalyticsAgent` composes queries and uses `credentials.json` to authenticate. GA4 `propertyId` must be passed in requests needing analytics.
- **LLM**: configured in `app/llm/client.py` using `LITELLM_API_KEY`. The client currently uses OpenAI-like `OpenAI` wrapper and a custom `base_url` in the code; update `base_url` or API config as needed for your provider.

---

## Usage Examples üìã

POST /query

Request body examples (JSON):

- SEO-only question:
```json
{ "query": "Show me pages with missing meta descriptions", "propertyId": null }
```

- GA4-only question (requires propertyId):
```json
{ "query": "What were total users and sessions in the last 30 days?", "propertyId": "123456789" }
```

- Combined question:
```json
{ "query": "Which landing pages had the largest drop in sessions and have broken titles?", "propertyId": "123456789" }
```

Response: plain text final answer (generated by the LLM); agent outputs are available internally and also returned by the orchestrator when using the Python API directly.

Curl example:
```bash
curl -X POST "http://localhost:8080/query" \
  -H "Content-Type: application/json" \
  -d '{"query":"What pages had the most sessions last month?","propertyId":"123456789"}'
```

---

## Assumptions & Limitations ‚ö†Ô∏è

- **Allowed GA4 fields**: The analytics agent can only use fields listed in `ga4_allowed_fields.txt`. If the LLM maps to a non-listed field, it will be rejected.
- **Spreadsheet format**: Screaming Frog exports must be uploaded to Google Sheets with consistent columns. The union builder expects an `Address` column to identify pages.
- **Execution safety**: SEO agent executes pandas code generated by the LLM via `exec()`. This is powerful but potentially unsafe ‚Äî do not run untrusted LLM code in production without sandboxing or strict validation.
- **No authentication**: The API currently does not enforce authentication/authorization. Add auth (API keys, OAuth, etc.) before exposing publicly.
- **Secrets in repo**: This repository currently included `credentials.json` and `.env` locally. **Rotate and remove any leaked keys** before sharing the repo. Use secure secret storage in production.
- **LLM behavior**: The system assumes the LLM returns well-formed content (JSON for analytics plans, pandas code for SEO). The LLM may occasionally return malformed content; the code tries to parse and report errors but manual corrections may be required.

---

## License

MIT License ¬© 2025

---
